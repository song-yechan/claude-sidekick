/// OCR ì„œë¹„ìŠ¤
///
/// ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
///
/// ì „ëµ:
/// 1. ML Kit (ì˜¨ë””ë°”ì´ìŠ¤) ìš°ì„  ì‹œë„ - ë¹ ë¥´ê³  ë¬´ë£Œ
/// 2. ì‹¤íŒ¨ ì‹œ Cloud Vision API í´ë°± - ë” ì •í™•í•¨
///
/// ì‚¬ìš©í•˜ëŠ” ì™¸ë¶€ ì„œë¹„ìŠ¤:
/// - Google ML Kit (ì˜¨ë””ë°”ì´ìŠ¤ OCR)
/// - Google Vision API (í´ë¼ìš°ë“œ OCR): Supabase Edge Function(ocr-image)ì„ í†µí•´ í˜¸ì¶œ
library;

import 'dart:convert';
import 'dart:io';
import 'dart:typed_data';
import 'package:google_mlkit_text_recognition/google_mlkit_text_recognition.dart';
import 'package:path_provider/path_provider.dart';
import '../core/supabase.dart';

/// OcrService ì¸í„°í˜ì´ìŠ¤
///
/// í…ŒìŠ¤íŠ¸ì—ì„œ Mock êµ¬í˜„ì²´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
abstract class IOcrService {
  Future<String> extractText(Uint8List imageBytes);
  Future<OcrResult> processImage(Uint8List imageBytes);
}

/// OCR ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
///
/// ML Kit ì˜¨ë””ë°”ì´ìŠ¤ OCRì„ ìš°ì„  ì‚¬ìš©í•˜ê³ ,
/// ì‹¤íŒ¨ ì‹œ Cloud Vision APIë¡œ í´ë°±í•©ë‹ˆë‹¤.
class OcrService implements IOcrService {
  /// ML Kit í…ìŠ¤íŠ¸ ì¸ì‹ê¸° (í•œê¸€ + ë¼í‹´)
  final TextRecognizer _textRecognizer = TextRecognizer(
    script: TextRecognitionScript.korean,
  );

  /// ML Kit ì‹ ë¢°ë„ ì„ê³„ê°’ (ì´ ê°’ ë¯¸ë§Œì´ë©´ Cloud Vision í´ë°±)
  static const double _minConfidence = 0.5;

  /// ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (OCR).
  ///
  /// [imageBytes] ì²˜ë¦¬í•  ì´ë¯¸ì§€ì˜ ë°”ì´íŠ¸ ë°ì´í„°
  ///
  /// 1ì°¨: ML Kit (ì˜¨ë””ë°”ì´ìŠ¤) ì‹œë„
  /// 2ì°¨: ì‹¤íŒ¨ ì‹œ Cloud Vision API í´ë°±
  ///
  /// ë°˜í™˜ê°’: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¬¸ìì—´
  /// ì˜ˆì™¸: OCR ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ Exception ë°œìƒ
  @override
  Future<String> extractText(Uint8List imageBytes) async {
    print('ğŸ“· OCR: Starting text extraction...');

    // 1ì°¨: ML Kit ì‹œë„
    try {
      final mlKitResult = await _extractWithMlKit(imageBytes);

      if (mlKitResult.isValid) {
        print('ğŸ“· OCR: ML Kit succeeded (${mlKitResult.text.length} chars, confidence: ${mlKitResult.confidence.toStringAsFixed(2)})');
        return mlKitResult.text;
      }

      print('ğŸ“· OCR: ML Kit confidence too low (${mlKitResult.confidence.toStringAsFixed(2)}), falling back to Cloud Vision');
    } catch (e) {
      print('ğŸ“· OCR: ML Kit failed: $e, falling back to Cloud Vision');
    }

    // 2ì°¨: Cloud Vision API í´ë°±
    return _extractWithCloudVision(imageBytes);
  }

  /// ML Kit (ì˜¨ë””ë°”ì´ìŠ¤)ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  Future<_MlKitResult> _extractWithMlKit(Uint8List imageBytes) async {
    print('ğŸ“· OCR: Trying ML Kit (on-device)...');

    // Uint8Listë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (ML Kitì€ íŒŒì¼ ê²½ë¡œ í•„ìš”)
    final tempDir = await getTemporaryDirectory();
    final tempFile = File('${tempDir.path}/ocr_temp_${DateTime.now().millisecondsSinceEpoch}.jpg');
    await tempFile.writeAsBytes(imageBytes);

    try {
      final inputImage = InputImage.fromFilePath(tempFile.path);
      final recognizedText = await _textRecognizer.processImage(inputImage);

      // ë¸”ë¡ì´ ì—†ìœ¼ë©´ ì‹¤íŒ¨
      if (recognizedText.blocks.isEmpty) {
        print('ğŸ“· OCR: ML Kit found no text blocks');
        return _MlKitResult(text: '', confidence: 0.0, isValid: false);
      }

      // í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° (ë¼ì¸ ë‹¨ìœ„)
      final confidences = recognizedText.blocks
          .expand((block) => block.lines)
          .where((line) => line.confidence != null)
          .map((line) => line.confidence!)
          .toList();

      final avgConfidence = confidences.isEmpty
          ? 0.0
          : confidences.fold(0.0, (sum, c) => sum + c) / confidences.length;

      print('ğŸ“· OCR: ML Kit extracted ${recognizedText.text.length} chars, '
          '${recognizedText.blocks.length} blocks, '
          'avg confidence: ${avgConfidence.toStringAsFixed(2)}');

      return _MlKitResult(
        text: recognizedText.text,
        confidence: avgConfidence,
        isValid: recognizedText.text.isNotEmpty && avgConfidence >= _minConfidence,
      );
    } finally {
      // ì„ì‹œ íŒŒì¼ ì •ë¦¬
      if (await tempFile.exists()) {
        await tempFile.delete();
      }
    }
  }

  /// Cloud Vision APIë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í´ë°±)
  Future<String> _extractWithCloudVision(Uint8List imageBytes) async {
    print('ğŸ“· OCR: Using Cloud Vision API (fallback)...');

    final base64Image = base64Encode(imageBytes);
    print('ğŸ“· OCR: Image base64 length: ${base64Image.length}');

    final response = await supabase.functions.invoke(
      'ocr-image',
      body: {
        'imageBase64': base64Image,
      },
    );

    print('ğŸ“· OCR: Cloud Vision response status: ${response.status}');

    if (response.status >= 400) {
      final errorMsg = response.data?['error'] ?? response.data?['details'] ?? 'Unknown error';
      throw Exception('$errorMsg (${response.status})');
    }

    if (response.data == null) {
      throw Exception('OCR ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤');
    }

    final text = response.data['text'] as String? ?? '';
    print('ğŸ“· OCR: Cloud Vision extracted ${text.length} chars');
    return text;
  }

  /// ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
  ///
  /// [imageBytes] ì²˜ë¦¬í•  ì´ë¯¸ì§€ì˜ ë°”ì´íŠ¸ ë°ì´í„°
  ///
  /// ë°˜í™˜ê°’: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ OcrResult ê°ì²´
  @override
  Future<OcrResult> processImage(Uint8List imageBytes) async {
    final extractedText = await extractText(imageBytes);

    return OcrResult(
      originalText: extractedText,
    );
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _textRecognizer.close();
  }
}

/// OCR ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë‹´ëŠ” í´ë˜ìŠ¤
class OcrResult {
  /// OCRë¡œ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸
  final String originalText;

  OcrResult({
    required this.originalText,
  });
}

/// ML Kit ê²°ê³¼ë¥¼ ë‹´ëŠ” ë‚´ë¶€ í´ë˜ìŠ¤
class _MlKitResult {
  final String text;
  final double confidence;
  final bool isValid;

  _MlKitResult({
    required this.text,
    required this.confidence,
    required this.isValid,
  });
}
